{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Financial Data For Machine Learning\n",
    "\n",
    "In this notebook we explain various ways of handling financial timeseries data. If you have a data science project involving timeseries, this notebook might help you at handling this particular kind of data. Indeed, when it comes to training machine learning models, the data should be handled decently to make the training process easy and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data.\n",
    "\n",
    "The data we load here is provided by us. It is the result of REST API endpoints gathered on the binance exchange platform for the BCT/USDT pair. The prices were recorded every 2s between first of september and end of november. We provide OHLCA data from 10 minutes, 30 minutes and 1 hour. Feel free to test this notebook with your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters.\n",
    "PATH = \"dataset\"\n",
    "SYMBOL = \"btcusdt\"\n",
    "DATASET = \"ohlc\"\n",
    "PERIOD = 600\n",
    "\n",
    "# Set the filename name for the training and test dataset. \n",
    "FILENAME_TR = \"binance_{}_{}_period_{}_{}.csv\".format(SYMBOL, DATASET, PERIOD, \"train\")\n",
    "FILENAME_TE = \"binance_{}_{}_period_{}_{}.csv\".format(SYMBOL, DATASET, PERIOD, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a fucntion to convert the csv dataset into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path, filename):\n",
    "    \"\"\"Load the filename as pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path + \"/\" + filename)\n",
    "    df = df.set_index(\"time\")\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = load(PATH, FILENAME_TR)\n",
    "df_te = load(PATH, FILENAME_TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualise the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the training dataset.\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_tr.index.values, df_tr[\"avg\"].values, color=\"b\")\n",
    "plt.plot(df_tr.index.values, df_tr[\"high\"].values, color=\"r\")\n",
    "plt.plot(df_tr.index.values, df_tr[\"low\"].values, color=\"g\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()\n",
    "\n",
    "# Display the test dataset.\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_te.index.values, df_te[\"avg\"].values, color=\"b\")\n",
    "plt.plot(df_te.index.values, df_te[\"high\"].values, color=\"r\")\n",
    "plt.plot(df_te.index.values, df_te[\"low\"].values, color=\"g\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalisation methods.\n",
    "\n",
    "We have a dataset $X \\in \\mathbb{R}^{T \\times n}$ where $T$ is the length of the timeseries we loaded. In order to train a machine learning algorithm, we have to draw samples from the given data. So we have to extract as many samples as possible from the given dataset, i.e. timeseries with a shorter length that we will call $lk$. In order the build a dataset,\n",
    "\n",
    "$$\n",
    "X = [ X_1, X_2, ..., X_m]\n",
    "$$\n",
    "\n",
    "where $m \\in \\mathbb{N}$ and $X_i \\in \\mathbb{R}^{N \\times n}$ \n",
    "\n",
    "Once this step has been performed, we will have to normalise the timeseries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Windowing.\n",
    "\n",
    "We provide here a function that performes the timeseries's windowing over a specified look back horizon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(df, lookback):\n",
    "    \"\"\"Window the timeseries df.\n",
    "    \n",
    "    :param df: the timeseries.\n",
    "    :type df: pandas dataframe.\n",
    "    :param lookback: the lookback horizon.\n",
    "    :type lookback: int.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for k in range(lookback):\n",
    "        s = lookback - k - 1        \n",
    "        dfs = df.shift(s)\n",
    "        data.append(dfs)\n",
    "    return pd.concat(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Mean and standard deviation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_std(df, lookback, mean=None, std=None):\n",
    "    \"\"\"Normalise the timeseries df with the pivot method.\n",
    "    \n",
    "    :param df: the timeseries.\n",
    "    :type df: pandas dataframe.\n",
    "    :param lookback: the lookback horizon.\n",
    "    :type lookback: int.\n",
    "    \"\"\"\n",
    "    eps = 1.0E-8\n",
    "    data = []\n",
    "    \n",
    "    if mean is None:\n",
    "        mean = df.mean()\n",
    "    if std is None:\n",
    "        std =df.std()\n",
    "    \n",
    "    for k in range(lookback):\n",
    "        s = lookback - k - 1\n",
    "        dfs = ( df.shift(s) - mean ) / ( std + eps )\n",
    "        data.append(dfs)\n",
    "        \n",
    "    return pd.concat(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Pivot method.\n",
    "\n",
    "For a timeseries given as\n",
    "\n",
    "$$\n",
    "x = [x_1, x_2, ..., x_N]\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$ N \\in \\mathbb{N}$$\n",
    "\n",
    "The pivot method normalisation method is computed as follows\n",
    "\n",
    "$$ \n",
    "z_{t} = 100 ( \\frac{x_{t}}{x_{0}} - 1 ) \n",
    "\\; \\text{where} \\;\n",
    "t \\in  [1, N]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_pvt(df, lookback, log=False):\n",
    "    \"\"\"Normalise the timeseries df with the pivot method.\n",
    "    \n",
    "    :param df: the timeseries.\n",
    "    :type df: pandas dataframe.\n",
    "    :param lookback: the lookback horizon.\n",
    "    :type lookback: int.\n",
    "    \"\"\"\n",
    "    eps = 1.0E-8\n",
    "    data = []\n",
    "    for k in range(lookback):\n",
    "        s = lookback - k - 1\n",
    "        if log is False:\n",
    "            dfs = 100 * ( df.shift(s) / ( df[[\"avg\"]] + eps ) - 1.0 )\n",
    "        else:\n",
    "            dfs = 100 * ( np.log(df.shift(s)) - np.log(df) )\n",
    "        data.append(dfs)\n",
    "    return pd.concat(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Percentage change method\n",
    "\n",
    "For a timeseries given as\n",
    "\n",
    "$$\n",
    "x = [x_1, x_2, ..., x_N]\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$ N \\in \\mathbb{N}$$\n",
    "\n",
    "The percentage change normalisation method is computed as follows,\n",
    "\n",
    "$$ \n",
    "z_{t} = 100 ( \\frac{x_{t}}{x_{t-1}} - 1 ) \n",
    "\\; \\text{where} \\;\n",
    "t \\in  [1, N]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_pct(df, lookback, log=False):\n",
    "    \"\"\"Normalise the timeseries df with the pct method.\n",
    "    \n",
    "    :param df: the timeseries.\n",
    "    :type df: pandas dataframe.\n",
    "    :param lookback: the lookback horizon.\n",
    "    :type lookback: int.\n",
    "    \"\"\"\n",
    "    eps = 1.0E-8\n",
    "    data = []\n",
    "    for k in range(lookback):\n",
    "        s = lookback -k - 1\n",
    "        if log is False:\n",
    "            dfs = 100 * ( df.shift(s) / ( df.shift(s+1) + eps ) - 1.0 )\n",
    "        else:\n",
    "            dfs = 100 * ( np.log( df.shift(s) / ( df.shift(s+1) + eps)))\n",
    "        data.append(dfs)\n",
    "    return pd.concat(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisation\n",
    "\n",
    "We can now visualise the result of the normalisation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LK = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df):\n",
    "    arr = df.corr()\n",
    "    plt.figure()\n",
    "    imgplot = plt.imshow(arr)\n",
    "    imgplot.set_cmap(\"jet\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Visualise mean and std method.\n",
    "\n",
    "The following visualisation shows why the mean and std method is not suited for timeseries data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percetange change normalised timeseries.\n",
    "data_std_tr = normalise_std(df_tr, LK).values.reshape(len(df_tr), LK, -1)\n",
    "data_std_te = normalise_std(df_te, LK, df_tr.mean(), df_tr.std()).values.reshape(len(df_te), LK, -1)\n",
    "\n",
    "# Histogram.\n",
    "plt.figure()\n",
    "hista = plt.hist(data_std_tr.reshape(-1,1), 500, density=True, facecolor=\"b\", alpha=0.50, label=\"tr\")\n",
    "hista = plt.hist(data_std_te.reshape(-1,1), 500, density=True, facecolor=\"g\", alpha=0.50, label=\"te\")\n",
    "plt.xlim([-1, 1])\n",
    "plt.title(\"Percentage change normalisation method.\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std_tr = normalise_std(df_tr, LK)\n",
    "plot_corr(data_std_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Visualise percentage change method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percetange change normalised timeseries.\n",
    "data_pvt_tr = normalise_pvt(df_tr, LK).values.reshape(len(df_tr), LK, -1)\n",
    "data_pvt_te = normalise_pvt(df_te, LK).values.reshape(len(df_te), LK, -1)\n",
    "\n",
    "# Histogram.\n",
    "plt.figure()\n",
    "hista = plt.hist(data_pvt_tr.reshape(-1,1), 100, density=True, facecolor=\"b\", alpha=0.50)\n",
    "hista = plt.hist(data_pvt_te.reshape(-1,1), 100, density=True, facecolor=\"g\", alpha=0.50)\n",
    "plt.xlim([99, 101])\n",
    "plt.title(\"Percentage change normalisation method.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Visualise percentage change method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percetange change normalised timeseries.\n",
    "data_pct_tr = normalise_pct(df_tr, LK).values.reshape(len(df_tr), LK, -1)\n",
    "data_pct_te = normalise_pct(df_te, LK).values.reshape(len(df_te), LK, -1)\n",
    "\n",
    "# Histogram.\n",
    "plt.figure()\n",
    "hista = plt.hist(data_pct_tr.reshape(-1,1), 500, density=True, facecolor=\"b\", alpha=0.50)\n",
    "hista = plt.hist(data_pct_te.reshape(-1,1), 500, density=True, facecolor=\"g\", alpha=0.50)\n",
    "plt.xlim([-1, 1])\n",
    "plt.title(\"Percentage change normalisation method.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_pct = normalise_pvt(df_tr, 16)\n",
    "\n",
    "print(df_tr.shape)\n",
    "print(df_tr_pct.shape)\n",
    "    \n",
    "plot_corr(df_tr_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
